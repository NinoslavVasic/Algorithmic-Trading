{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newsapi in /usr/local/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from newsapi) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->newsapi) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->newsapi) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->newsapi) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->newsapi) (1.25.8)\n",
      "Collecting news\n",
      "  Downloading news-1.0.zip (786 bytes)\n",
      "Building wheels for collected packages: news\n",
      "  Building wheel for news (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for news: filename=news-1.0-py3-none-any.whl size=1247 sha256=1ef9594d433a0a65442e81b5be174a7b6ff003d6d6dfb2f33051fd22c4e256c8\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/0f/68/bd4f1f1d7096501a76e952a5141aaa0802a51f710b6b743a15\n",
      "Successfully built news\n",
      "Installing collected packages: news\n",
      "Successfully installed news-1.0\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for os\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'newsapi.newsapi_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-31d4e59f934f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0miexfinance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstocks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnewsapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewsapi_client\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNewsApiClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'newsapi.newsapi_client'"
     ]
    }
   ],
   "source": [
    "!pip install newsapi\n",
    "!pip install news\n",
    "!pip install os\n",
    "\n",
    "from iexfinance.stocks import Stock\n",
    "import pandas as pd\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0ea1f34f88e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read your api key environment variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"news_api\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Read your api key environment variable\n",
    "\n",
    "api_key = os.getenv(\"news_api\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start date: 2020-03-11\n",
      "\n",
      "end date: 2020-04-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set date range for downloading headlines\n",
    "start_date = date.today() - timedelta(weeks=4)# ahere we can input exact timing we want to download data for, in days....\n",
    "end_date = date.today()\n",
    "\n",
    "print(f\"\"\"\n",
    "start date: {start_date}\n",
    "\n",
    "end date: {end_date}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the S&P500 news articles\n",
    "\n",
    "def get_headlines(keyword):\n",
    "    \"\"\"\n",
    "    Using a given keywords, connects to NewsApi.org servers to download\n",
    "    headlines for a given range of dates for that keyword.\n",
    "    \n",
    "    Params\n",
    "    -------------\n",
    "    keywords: string, the words you want to search for in headlines\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    all_articles: list, a collection of articles ordered by data\n",
    "    all_dates: list, a collection of dates associated with the collection all_headlines\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # create an empty list to store headlines    \n",
    "    all_headlines = []\n",
    "    \n",
    "    # create an empty list to store the dates\n",
    "    all_dates = []\n",
    "    \n",
    "    # initalize the date variable we will be looping through\n",
    "    # the query will look for headlines on a given date\n",
    "    date = end_date\n",
    "    \n",
    "    # human friendly output\n",
    "    print(f\"Fetching news about: {keyword}\")\n",
    "    print('*' * 30) # prints a string of asterisks repeated 30 times\n",
    "    \n",
    "    # begin loop\n",
    "    # date starts with today (defined outside of function above)\n",
    "    # at the end of loop we reassign date to be the value of the day before the last loop run\n",
    "    # eventually the date will be before the last date we want to run (defined outside loop above)\n",
    "    \n",
    "    while date > start_date:\n",
    "        \n",
    "        #human friendly output\n",
    "        print(f'retrieving news from: {date}')\n",
    "        \n",
    "        # run a query using the news api client\n",
    "        # querying for the keyword for the given date we are looping through\n",
    "        articles = newsapi.get_everything(\n",
    "                            q=keyword,\n",
    "                            from_param=str(date),\n",
    "                            to=str(date),\n",
    "                            language='en',\n",
    "                            sort_by='relevancy',\n",
    "                            page=1\n",
    "        )\n",
    "        \n",
    "        # create an empty list to store headline results\n",
    "        headlines=[]\n",
    "        \n",
    "        # loop through all the articles returned for a given day and store\n",
    "        # the title of the article to headlines list\n",
    "        for i in range(0, len(articles['articles'])):\n",
    "            headlines.append(articles['articles'][i]['title'])\n",
    "        \n",
    "        # append the headlines list to the all_headlines list for the keyword\n",
    "        all_headlines.append(headlines)\n",
    "        \n",
    "        # append the date we just ran for so it can used for aligning with the returns data and other\n",
    "        # headlines\n",
    "        all_dates.append(date)\n",
    "        \n",
    "        # step back one more day in time and reevalute the while \n",
    "        # then determine if another loop is appropriate\n",
    "        date = date-timedelta(days=1)\n",
    "    \n",
    "    return all_headlines, all_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news about: S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "Fetching news about: Donald Trump AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "Fetching news about: Leading economists AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "Fetching news about: Jim Cramer AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "Fetching news about: Jamie Dimon AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "Fetching news about: David Solomon AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "Fetching news about: Lloyd Blankfein AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "Fetching news about: Michael Corbat AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-08\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n"
     ]
    }
   ],
   "source": [
    "# test the function, download news headlines and get dates\n",
    "SP500_headlines, dates = get_headlines(\"S&P 500\")\n",
    "Trump_headlines, _ = get_headlines('Donald Trump AND S&P 500')\n",
    "Economists_headlines, _ = get_headlines('Leading economists AND S&P 500')\n",
    "Cramer_headlines, _ = get_headlines('Jim Cramer AND S&P 500')\n",
    "Dimon_headlines, _ = get_headlines('Jamie Dimon AND S&P 500')\n",
    "Solomon_headlines, _ = get_headlines('David Solomon AND S&P 500')\n",
    "Lloyd_headlines, _ = get_headlines('Lloyd Blankfein AND S&P 500')\n",
    "Corbat_headlines, _ = get_headlines('Michael Corbat AND S&P 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total headlines returned\n",
    "headlines = 0\n",
    "for date in SP500_headlines:\n",
    "    headlines += len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total headlines returned\n",
    "headlines = 0\n",
    "for date in Economists_headlines:\n",
    "    headlines += len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headline_sentiment_summarizer_avg(headlines):\n",
    "    \"\"\"\n",
    "    Uses VADER SentimentIntensityAnalyzer to score headlines. \n",
    "    \n",
    "    Params\n",
    "    -----------------------------\n",
    "    headlines: list of lists, collection of headlines or other text to be score.\n",
    "                The outer list is the collection of headlines by days, where\n",
    "                each entry represents a day, and the inner list for that day\n",
    "                is a collection of headlines\n",
    "    \n",
    "    Returns\n",
    "    ------------------------------\n",
    "    sentiment: float, average score for all headlines provided\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create an empty list to store all scored days\n",
    "    sentiment = []\n",
    "    \n",
    "    # loop through each day in headlines (loop through outer list)\n",
    "    for day in headlines:\n",
    "        \n",
    "        # an empty list to store the sentiment score values for each\n",
    "        # headline in a given day\n",
    "        day_score = []\n",
    "        \n",
    "        # loop through each headline for a given day (inner loop)\n",
    "        for h in day:\n",
    "            \n",
    "            # pass if no headlines for a day\n",
    "            if h == None:\n",
    "                continue\n",
    "                \n",
    "            # otherwise, score the headline and add to day_score    \n",
    "            else:\n",
    "                day_score.append(sid.polarity_scores(h)[\"compound\"])\n",
    "        \n",
    "        # once all headlines for a day are scored (inner loop finished)\n",
    "        # get the average value of the headlines for a given day\n",
    "        # (average of inner loop results) and append as the daily average score\n",
    "        sentiment.append(sum(day_score) / len(day_score))\n",
    "        \n",
    "    # return the vector or column of scores each related to one day of headlines\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each topic, produce a vector or column of average sentiment scores\n",
    "# for each day\n",
    "\n",
    "SP500_avg = headline_sentiment_summarizer_avg(SP500_headlines)\n",
    "Trump_avg = headline_sentiment_summarizer_avg(Trump_headlines)\n",
    "economy_avg = headline_sentiment_summarizer_avg(Economists_headlines)\n",
    "Cramer_avg = headline_sentiment_summarizer_avg(Cramer_headlines)\n",
    "Dimon_avg = headline_sentiment_summarizer_avg(Dimon_headlines)\n",
    "Solomon_avg = headline_sentiment_summarizer_avg(Solomon_headlines)\n",
    "Lloyd_avg = headline_sentiment_summarizer_avg(Lloyd_headlines)\n",
    "Corbat_avg = headline_sentiment_summarizer_avg(Corbat_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it all in a dataframe for easier analysis and movement\n",
    "\n",
    "topic_sentiments = pd.DataFrame(\n",
    "    {\n",
    "        'SP500': SP500_avg,\n",
    "        'Trump': Trump_avg,\n",
    "        'Economists': economy_avg,\n",
    "        'Cramer': Cramer_avg,\n",
    "        'Dimon': Dimon_avg,\n",
    "        'Solomon': Solomon_avg ,\n",
    "        'Lloyd': Lloyd_avg, \n",
    "        'Corbat': Corbat_avg\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-associate the dates with the average scores produced\n",
    "\n",
    "topic_sentiments.index = pd.to_datetime(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Troy- import stocks df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join or merge the sentiments with the core SPY returns dataframe\n",
    "#topic_sentiments = XXXXXX_df.join(topic_sentiments).dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Base Python)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:environment/base-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
