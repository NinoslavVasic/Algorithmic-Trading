{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iexfinance.stocks import Stock\n",
    "import pandas as pd\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your api key environment variable\n",
    "\n",
    "api_key = os.getenv(\"news_api\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start date: 2020-03-10\n",
      "\n",
      "end date: 2020-04-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set date range for downloading headlines\n",
    "start_date = date.today() - timedelta(weeks=4)# ahere we can input exact timing we want to download data for, in days....\n",
    "end_date = date.today()\n",
    "\n",
    "print(f\"\"\"\n",
    "start date: {start_date}\n",
    "\n",
    "end date: {end_date}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the S&P500 news articles\n",
    "\n",
    "def get_everything(keywords):\n",
    "    \"\"\"\n",
    "    Using a given keywords, connects to NewsApi.org servers to download\n",
    "    headlines for a given range of dates for that keyword.\n",
    "    \n",
    "    Params\n",
    "    -------------\n",
    "    keywords: string, the words you want to search for in headlines\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    all_articles: list, a collection of articles ordered by data\n",
    "    all_dates: list, a collection of dates associated with the collection all_headlines\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # create an empty list to store headlines    \n",
    "    all_headlines = []\n",
    "    \n",
    "    # create an empty list to store the dates\n",
    "    all_dates = []\n",
    "    \n",
    "    # initalize the date variable we will be looping through\n",
    "    # the query will look for headlines on a given date\n",
    "    date = end_date\n",
    "    \n",
    "    # human friendly output\n",
    "    print(f\"Fetching news about: {keywords}\")\n",
    "    print('*' * 30) # prints a string of asterisks repeated 30 times\n",
    "    \n",
    "    # begin loop\n",
    "    # date starts with today (defined outside of function above)\n",
    "    # at the end of loop we reassign date to be the value of the day before the last loop run\n",
    "    # eventually the date will be before the last date we want to run (defined outside loop above)\n",
    "    \n",
    "    while date > start_date:\n",
    "        \n",
    "        #human friendly output\n",
    "        print(f'retrieving news from: {date}')\n",
    "        \n",
    "        # run a query using the news api client\n",
    "        # querying for the keyword for the given date we are looping through\n",
    "        articles = newsapi.get_everything(\n",
    "                            q=keyword,\n",
    "                            from_param=str(date),\n",
    "                            to=str(date),\n",
    "                            language='en',\n",
    "                            sort_by='relevancy',\n",
    "                            page=1\n",
    "        )\n",
    "        \n",
    "        # create an empty list to store headline results\n",
    "        headlines=[]\n",
    "        \n",
    "        # loop through all the articles returned for a given day and store\n",
    "        # the title of the article to headlines list\n",
    "        for i in range(0, len(articles['articles'])):\n",
    "            headlines.append(articles['articles'][i]['title'])\n",
    "        \n",
    "        # append the headlines list to the all_headlines list for the keyword\n",
    "        all_headlines.append(headlines)\n",
    "        \n",
    "        # append the date we just ran for so it can used for aligning with the returns data and other\n",
    "        # headlines\n",
    "        all_dates.append(date)\n",
    "        \n",
    "        # step back one more day in time and reevalute the while \n",
    "        # then determine if another loop is appropriate\n",
    "        date = date-timedelta(days=1)\n",
    "    \n",
    "    return all_headlines, all_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news about: S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "retrieving news from: 2020-03-11\n",
      "Fetching news about: Donald Trump AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "retrieving news from: 2020-03-11\n",
      "Fetching news about: Leading economists on S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "retrieving news from: 2020-03-11\n",
      "Fetching news about: Jim Cramer AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "retrieving news from: 2020-03-11\n",
      "Fetching news about: Jamie Dimon AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "retrieving news from: 2020-03-11\n",
      "Fetching news about: David Solomon AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n",
      "retrieving news from: 2020-03-26\n",
      "retrieving news from: 2020-03-25\n",
      "retrieving news from: 2020-03-24\n",
      "retrieving news from: 2020-03-23\n",
      "retrieving news from: 2020-03-22\n",
      "retrieving news from: 2020-03-21\n",
      "retrieving news from: 2020-03-20\n",
      "retrieving news from: 2020-03-19\n",
      "retrieving news from: 2020-03-18\n",
      "retrieving news from: 2020-03-17\n",
      "retrieving news from: 2020-03-16\n",
      "retrieving news from: 2020-03-15\n",
      "retrieving news from: 2020-03-14\n",
      "retrieving news from: 2020-03-13\n",
      "retrieving news from: 2020-03-12\n",
      "retrieving news from: 2020-03-11\n",
      "Fetching news about: Lloyd Blankfein AND S&P 500\n",
      "******************************\n",
      "retrieving news from: 2020-04-07\n",
      "retrieving news from: 2020-04-06\n",
      "retrieving news from: 2020-04-05\n",
      "retrieving news from: 2020-04-04\n",
      "retrieving news from: 2020-04-03\n",
      "retrieving news from: 2020-04-02\n",
      "retrieving news from: 2020-04-01\n",
      "retrieving news from: 2020-03-31\n",
      "retrieving news from: 2020-03-30\n",
      "retrieving news from: 2020-03-29\n",
      "retrieving news from: 2020-03-28\n",
      "retrieving news from: 2020-03-27\n"
     ]
    },
    {
     "ename": "NewsAPIException",
     "evalue": "{'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 500 requests over a 24 hour period (250 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-92264c8f06f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mDimon_headlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Jamie Dimon AND S&P 500'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mSolomon_headlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'David Solomon AND S&P 500'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mLloyd_headlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Lloyd Blankfein AND S&P 500'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mCorbat_headlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_headlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Michael Corbat AND S&P 500'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b09d3dcdeb97>\u001b[0m in \u001b[0;36mget_headlines\u001b[1;34m(keyword)\u001b[0m\n\u001b[0;32m     50\u001b[0m                             \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                             \u001b[0msort_by\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relevancy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                             \u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         )\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3.0\\lib\\site-packages\\newsapi\\newsapi_client.py\u001b[0m in \u001b[0;36mget_everything\u001b[1;34m(self, q, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# Check Status of Request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNewsAPIException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 500 requests over a 24 hour period (250 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}"
     ]
    }
   ],
   "source": [
    "# test the function, download news headlines and get dates\n",
    "SP500_headlines, dates = get_everything(\"S&P 500\")\n",
    "Trump_headlines, _ = get_everything('Donald Trump AND S&P 500')\n",
    "Economists_headlines, _ = get_everything('Leading economists AND S&P 500')\n",
    "Cramer_headlines, _ = get_everything('Jim Cramer AND S&P 500')\n",
    "Dimon_headlines, _ = get_everything('Jamie Dimon AND S&P 500')\n",
    "Solomon_headlines, _ = get_everything('David Solomon AND S&P 500')\n",
    "Lloyd_headlines, _ = get_everything('Lloyd Blankfein AND S&P 500')\n",
    "Corbat_headlines, _ = get_everything('Michael Corbat AND S&P 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total headlines returned\n",
    "headlines = 0\n",
    "for date in SP500_headlines:\n",
    "    headlines += len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total headlines returned\n",
    "headlines = 0\n",
    "for date in Economists_headlines:\n",
    "    headlines += len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headline_sentiment_summarizer_avg(headlines):\n",
    "    \"\"\"\n",
    "    Uses VADER SentimentIntensityAnalyzer to score headlines. \n",
    "    \n",
    "    Params\n",
    "    -----------------------------\n",
    "    headlines: list of lists, collection of headlines or other text to be score.\n",
    "                The outer list is the collection of headlines by days, where\n",
    "                each entry represents a day, and the inner list for that day\n",
    "                is a collection of headlines\n",
    "    \n",
    "    Returns\n",
    "    ------------------------------\n",
    "    sentiment: float, average score for all headlines provided\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create an empty list to store all scored days\n",
    "    sentiment = []\n",
    "    \n",
    "    # loop through each day in headlines (loop through outer list)\n",
    "    for day in headlines:\n",
    "        \n",
    "        # an empty list to store the sentiment score values for each\n",
    "        # headline in a given day\n",
    "        day_score = []\n",
    "        \n",
    "        # loop through each headline for a given day (inner loop)\n",
    "        for h in day:\n",
    "            \n",
    "            # pass if no headlines for a day\n",
    "            if h == None:\n",
    "                continue\n",
    "                \n",
    "            # otherwise, score the headline and add to day_score    \n",
    "            else:\n",
    "                day_score.append(sid.polarity_scores(h)[\"compound\"])\n",
    "        \n",
    "        # once all headlines for a day are scored (inner loop finished)\n",
    "        # get the average value of the headlines for a given day\n",
    "        # (average of inner loop results) and append as the daily average score\n",
    "        sentiment.append(sum(day_score) / len(day_score))\n",
    "        \n",
    "    # return the vector or column of scores each related to one day of headlines\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each topic, produce a vector or column of average sentiment scores\n",
    "# for each day\n",
    "\n",
    "SP500_avg = headline_sentiment_summarizer_avg(SP500_headlines)\n",
    "Trump_avg = headline_sentiment_summarizer_avg(Trump_headlines)\n",
    "economy_avg = headline_sentiment_summarizer_avg(Economists_headlines)\n",
    "Cramer_avg = headline_sentiment_summarizer_avg(Cramer_headlines)\n",
    "gold_avg = headline_sentiment_summarizer_avg(gold_headlines)\n",
    "wuhan_avg = headline_sentiment_summarizer_avg(wuhan_headlines)\n",
    "corona_avg = headline_sentiment_summarizer_avg(corona_headlines)\n",
    "cancelled_avg = headline_sentiment_summarizer_avg(cancelled_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it all in a dataframe for easier analysis and movement\n",
    "\n",
    "topic_sentiments = pd.DataFrame(\n",
    "    {\n",
    "        'appl': aapl_avg,\n",
    "        'trade': trade_avg,\n",
    "        'economy': economy_avg,\n",
    "        'iphone': iphone_avg,\n",
    "        'gold': gold_avg,\n",
    "        'wuhan': wuhan_avg ,\n",
    "        'corona': corona_avg, \n",
    "        'cancelled': cancelled_avg\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
