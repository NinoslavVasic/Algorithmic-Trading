{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>p2_team 4 - Bermuda</h1>\n",
    "\n",
    "<h2>Team Members</h2>\n",
    "\n",
    "<p>Roger Hahn, Pedro Nunez, Ninoslav Vasic, Troy Draizen</p>\n",
    "\n",
    "<h2>Project scope:</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>S&amp;P 500 sentiment analysis from newsapi based on:</h1>\n",
    "\n",
    "<ol>\n",
    "<li><p>S&amp;P 500 - news - Headlines</p></li>\n",
    "<li><p>CNBCs Jim Cramer - statements - news headlines on S&amp;P 500</p></li>\n",
    "<li><p>US President Donald Trump - statements - news headlines on S&amp;P 500</p></li>\n",
    "\n",
    "\n",
    "should add alll others\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Initial imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#!pip install newsapi\n",
    "\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import newsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from newsapi.newsapi_client import NewsApiClient\n",
    "from newsapi import newsapi_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\19293\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from string import punctuation\n",
    "from nltk.corpus import reuters, stopwords\n",
    "from newsapi import NewsApiClient\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Headlines Sentiment\n",
    "\n",
    "Based on the news api we  pulled the latest news articles for S&P 500 and create a DataFrame of sentiment scores. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your api key environment variable\n",
    "\n",
    "api_key = \"3e339c6e32a94b3bb83af5dd6c0bc07b\"\n",
    "#len(api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start date: 2020-02-04\n",
      "\n",
      "end date: 2020-04-14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set date range for downloading headlines\n",
    "start_date = date.today() - timedelta(weeks=10)# ahere we can input exact timing we want to download data for, in days....\n",
    "end_date = date.today() #- timedelta(days=0)\n",
    "\n",
    "print(f\"\"\"\n",
    "start date: {start_date}\n",
    "\n",
    "end date: {end_date}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the S&P500 news articles\n",
    "\n",
    "#SP500_headlines = newsapi.get_sources()\n",
    "SP500_headlines = newsapi.get_everything(q=\"S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by Jim Cramer statements\n",
    "\n",
    "cramer_SP500_headlines = newsapi.get_everything(q=\" Jim Cramer AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by Donald Trump statements\n",
    "potus_SP500_headlines = newsapi.get_everything(q=\" Donald Trump AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by Jamie Dimon statements\n",
    "dimon_SP500_headlines = newsapi.get_everything(q=\" Jamie Dimon AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by Lloyd Blankfein statements\n",
    "blankfein_SP500_headlines = newsapi.get_everything(q=\"Lloyd Blankfein AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by David Solomon statements\n",
    "solomon_SP500_headlines = newsapi.get_everything(q=\"David Solomon AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by Michael Corbat statements\n",
    "corbat_SP500_headlines = newsapi.get_everything(q=\"Michael Corbat AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by lead economists statements\n",
    "economists_SP500_headlines = newsapi.get_everything(q=\"Lead Economists AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by Jerome Powel statements\n",
    "powel_SP500_headlines = newsapi.get_everything(q=\"Jerome Powel AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by FED statements\n",
    "fed_SP500_headlines = newsapi.get_everything(q=\"FED AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "# Fetch data on S&P 500 by Larry Fink statements\n",
    "fink_SP500_headlines = newsapi.get_everything(q=\"Larry Fink AND S&P 500\", page_size=50,language=\"en\", sort_by=\"publishedAt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles about S&P 500: 13838\n",
      "Total number of articles about S&P 500 by Jim Cramer: 82\n",
      "Total number of articles about S&P 500 by Donald Trump: 2074\n",
      "Total number of articles about S&P 500 by Jamie Dimon: 40\n",
      "Total number of articles about S&P 500 by Lloyd Blankfein: 12\n",
      "Total number of articles about S&P 500 by David Solomon: 8\n",
      "Total number of articles about S&P 500 by Michael Corbat: 2\n",
      "Total number of articles about S&P 500 by lead economists: 175\n",
      "Total number of articles about S&P 500 by Jerome Powel: 1\n",
      "Total number of articles about S&P 500 by FED officials: 2147\n",
      "Total number of articles about S&P 500 by Larry Fink: 18\n"
     ]
    }
   ],
   "source": [
    "# Print all publshed articles about S&P500\n",
    "print(f\"Total number of articles about S&P 500: {SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on Jim Cramer statements\n",
    "print(f\"Total number of articles about S&P 500 by Jim Cramer: {cramer_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on Donald Trump statements\n",
    "print(f\"Total number of articles about S&P 500 by Donald Trump: {potus_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on Jamie Dimon statements\n",
    "print(f\"Total number of articles about S&P 500 by Jamie Dimon: {dimon_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on Lloyd Blankfein statements\n",
    "print(f\"Total number of articles about S&P 500 by Lloyd Blankfein: {blankfein_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on David Solomon statements\n",
    "print(f\"Total number of articles about S&P 500 by David Solomon: {solomon_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on Michael Corbat statements\n",
    "print(f\"Total number of articles about S&P 500 by Michael Corbat: {corbat_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on lead economists statements\n",
    "print(f\"Total number of articles about S&P 500 by lead economists: {economists_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on Jerome Powel statements\n",
    "print(f\"Total number of articles about S&P 500 by Jerome Powel: {powel_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on FED statements\n",
    "print(f\"Total number of articles about S&P 500 by FED officials: {fed_SP500_headlines['totalResults']}\")\n",
    "\n",
    "# Print all publshed articles about S&P500 based on larry Fink statements\n",
    "print(f\"Total number of articles about S&P 500 by Larry Fink: {fink_SP500_headlines['totalResults']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SP500 Compound</th>\n",
       "      <th>SP500 Negative</th>\n",
       "      <th>SP500 Neutral</th>\n",
       "      <th>SP500 Positive</th>\n",
       "      <th>SP500 Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 15:55:21</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.000</td>\n",
       "      <td>the parnassus endeavor fund (trades, portfolio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14 15:43:51</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.047</td>\n",
       "      <td>looking at the chart below, it’s fair to say t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14 15:40:28</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.059</td>\n",
       "      <td>stock futures, premarket data and performance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14 15:40:27</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.128</td>\n",
       "      <td>tuesday morning brought some relief for invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-14 15:29:43</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>its been a rough couple of months for all inve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  SP500 Compound  SP500 Negative  SP500 Neutral  \\\n",
       "0 2020-04-14 15:55:21         -0.1779           0.045          0.955   \n",
       "1 2020-04-14 15:43:51          0.3182           0.000          0.953   \n",
       "2 2020-04-14 15:40:28          0.1027           0.049          0.892   \n",
       "3 2020-04-14 15:40:27          0.6908           0.000          0.872   \n",
       "4 2020-04-14 15:29:43          0.0000           0.000          1.000   \n",
       "\n",
       "   SP500 Positive                                         SP500 Text  \n",
       "0           0.000  the parnassus endeavor fund (trades, portfolio...  \n",
       "1           0.047  looking at the chart below, it’s fair to say t...  \n",
       "2           0.059  stock futures, premarket data and performance ...  \n",
       "3           0.128  tuesday morning brought some relief for invest...  \n",
       "4           0.000  its been a rough couple of months for all inve...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the S&P sentiment scores DataFrame\n",
    "SP500_sentiments = []\n",
    "\n",
    "for sp500_article in SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = sp500_article['publishedAt']\n",
    "        text = sp500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"SP500 Text\": text,\n",
    "            \"SP500 Compound\": compound,\n",
    "            \"SP500 Positive\": pos,\n",
    "            \"SP500 Negative\": neg,\n",
    "            \"SP500 Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "SP500_df = pd.DataFrame(SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\",\"SP500 Compound\",\"SP500 Negative\",\"SP500 Neutral\",\"SP500 Positive\",\"SP500 Text\"]\n",
    "SP500_df = SP500_df[cols]\n",
    "SP500_df['Date'] = pd.to_datetime(SP500_df['Date'], infer_datetime_format=True)\n",
    "#SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SP500 Compound    float64\n",
       "SP500 Negative    float64\n",
       "SP500 Neutral     float64\n",
       "SP500 Positive    float64\n",
       "SP500 Text         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cramer Compound</th>\n",
       "      <th>Cramer Negative</th>\n",
       "      <th>Cramer Neutral</th>\n",
       "      <th>Cramer Positive</th>\n",
       "      <th>Cramer Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 13:43:12</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.052</td>\n",
       "      <td>further action needed.\\r\\nmonetary/fiscal stim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14 13:01:36</td>\n",
       "      <td>-0.1548</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.057</td>\n",
       "      <td>stock futures jumped in early morning trading ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-13 23:27:42</td>\n",
       "      <td>-0.7184</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>cnbc's jim cramer has struck a \"hopeful\" new t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-13 13:00:08</td>\n",
       "      <td>-0.7184</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.000</td>\n",
       "      <td>neel kashkari, the head of the federal reserve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-12 13:59:03</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.170</td>\n",
       "      <td>this past week the s&amp;amp;p 500 went up 301 poi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Cramer Compound  Cramer Negative  Cramer Neutral  \\\n",
       "0 2020-04-14 13:43:12          -0.6124            0.156           0.792   \n",
       "1 2020-04-14 13:01:36          -0.1548            0.070           0.873   \n",
       "2 2020-04-13 23:27:42          -0.7184            0.140           0.860   \n",
       "3 2020-04-13 13:00:08          -0.7184            0.146           0.854   \n",
       "4 2020-04-12 13:59:03           0.6369            0.079           0.752   \n",
       "\n",
       "   Cramer Positive                                        Cramer Text  \n",
       "0            0.052  further action needed.\\r\\nmonetary/fiscal stim...  \n",
       "1            0.057  stock futures jumped in early morning trading ...  \n",
       "2            0.000  cnbc's jim cramer has struck a \"hopeful\" new t...  \n",
       "3            0.000  neel kashkari, the head of the federal reserve...  \n",
       "4            0.170  this past week the s&amp;p 500 went up 301 poi...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Jim Cramer S&P sentiment scores DataFrame\n",
    "cramer_SP500_sentiments = []\n",
    "\n",
    "for cramer_sp500_article in cramer_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = cramer_sp500_article['publishedAt']\n",
    "        text = cramer_sp500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        cramer_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Cramer Text\": text,\n",
    "            \"Cramer Compound\": compound,\n",
    "            \"Cramer Positive\": pos,\n",
    "            \"Cramer Negative\": neg,\n",
    "            \"Cramer Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "cramer_SP500_df = pd.DataFrame(cramer_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Cramer Compound\",\"Cramer Negative\",\"Cramer Neutral\",\"Cramer Positive\",\"Cramer Text\"]\n",
    "cramer_SP500_df = cramer_SP500_df[cols]\n",
    "cramer_SP500_df['Date'] = pd.to_datetime(cramer_SP500_df['Date'], infer_datetime_format=True)\n",
    "#cramer_SP500_df.set_index(('Date'), inplace=True)\n",
    "cramer_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Trump Compound</th>\n",
       "      <th>Trump Negative</th>\n",
       "      <th>Trump Neutral</th>\n",
       "      <th>Trump Positive</th>\n",
       "      <th>Trump Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 15:20:01</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.101</td>\n",
       "      <td>leaders of both the republican and democratic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14 15:20:01</td>\n",
       "      <td>-0.6369</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.095</td>\n",
       "      <td>leaders of both the republican and democratic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14 15:00:41</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.057</td>\n",
       "      <td>reuters: wall street rose more than 2per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14 13:45:45</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.117</td>\n",
       "      <td>wall street opened on a high note tuesday morn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-14 13:45:45</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.117</td>\n",
       "      <td>wall street opened on a high note tuesday morn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Trump Compound  Trump Negative  Trump Neutral  \\\n",
       "0 2020-04-14 15:20:01         -0.0772           0.087          0.812   \n",
       "1 2020-04-14 15:20:01         -0.6369           0.154          0.751   \n",
       "2 2020-04-14 15:00:41          0.3612           0.000          0.943   \n",
       "3 2020-04-14 13:45:45          0.6908           0.000          0.883   \n",
       "4 2020-04-14 13:45:45          0.6908           0.000          0.883   \n",
       "\n",
       "   Trump Positive                                         Trump Text  \n",
       "0           0.101  leaders of both the republican and democratic ...  \n",
       "1           0.095  leaders of both the republican and democratic ...  \n",
       "2           0.057  reuters: wall street rose more than 2per cent ...  \n",
       "3           0.117  wall street opened on a high note tuesday morn...  \n",
       "4           0.117  wall street opened on a high note tuesday morn...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Donald Trump S&P sentiment scores DataFrame\n",
    "potus_SP500_sentiments = []\n",
    "\n",
    "for potus_sp500_article in potus_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = potus_sp500_article['publishedAt']\n",
    "        text = potus_sp500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        potus_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Trump Text\": text,\n",
    "            \"Trump Compound\": compound,\n",
    "            \"Trump Positive\": pos,\n",
    "            \"Trump Negative\": neg,\n",
    "            \"Trump Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "potus_SP500_df = pd.DataFrame(potus_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Trump Compound\",\"Trump Negative\",\"Trump Neutral\",\"Trump Positive\",\"Trump Text\"]\n",
    "potus_SP500_df = potus_SP500_df[cols]\n",
    "\n",
    "potus_SP500_df['Date'] = pd.to_datetime(potus_SP500_df['Date'], infer_datetime_format=True)\n",
    "#potus_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "potus_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dimon Compound</th>\n",
       "      <th>Dimon Negative</th>\n",
       "      <th>Dimon Neutral</th>\n",
       "      <th>Dimon Positive</th>\n",
       "      <th>Dimon Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 15:23:33</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>stocks rose tuesday as investors considered si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14 13:33:34</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.058</td>\n",
       "      <td>toplinebank stocks have tumbled this year as t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14 13:30:18</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.108</td>\n",
       "      <td>getty images\\r\\ngetty images\\r\\nkey takeaways:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14 12:09:07</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.084</td>\n",
       "      <td>jamie dimon, ceo of jp morgan chase, appears o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-13 18:49:32</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.103</td>\n",
       "      <td>while no sector is immune to the virus batteri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Dimon Compound  Dimon Negative  Dimon Neutral  \\\n",
       "0 2020-04-14 15:23:33          0.0000           0.000          1.000   \n",
       "1 2020-04-14 13:33:34          0.3818           0.000          0.942   \n",
       "2 2020-04-14 13:30:18          0.4310           0.034          0.858   \n",
       "3 2020-04-14 12:09:07          0.4767           0.000          0.916   \n",
       "4 2020-04-13 18:49:32          0.2716           0.082          0.816   \n",
       "\n",
       "   Dimon Positive                                         Dimon Text  \n",
       "0           0.000  stocks rose tuesday as investors considered si...  \n",
       "1           0.058  toplinebank stocks have tumbled this year as t...  \n",
       "2           0.108  getty images\\r\\ngetty images\\r\\nkey takeaways:...  \n",
       "3           0.084  jamie dimon, ceo of jp morgan chase, appears o...  \n",
       "4           0.103  while no sector is immune to the virus batteri...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Jamie Dimon sentiment scores DataFrame\n",
    "dimon_SP500_sentiments = []\n",
    "\n",
    "for dimon_SP500_article in dimon_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = dimon_SP500_article['publishedAt']\n",
    "        text = dimon_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        dimon_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Dimon Text\": text,\n",
    "            \"Dimon Compound\": compound,\n",
    "            \"Dimon Positive\": pos,\n",
    "            \"Dimon Negative\": neg,\n",
    "            \"Dimon Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "dimon_SP500_df = pd.DataFrame(dimon_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Dimon Compound\",\"Dimon Negative\",\"Dimon Neutral\",\"Dimon Positive\",\"Dimon Text\"]\n",
    "dimon_SP500_df = dimon_SP500_df[cols]\n",
    "\n",
    "dimon_SP500_df['Date'] = pd.to_datetime(dimon_SP500_df['Date'], infer_datetime_format=True)\n",
    "#dimon_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "dimon_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Blankfein Compound</th>\n",
       "      <th>Blankfein Negative</th>\n",
       "      <th>Blankfein Neutral</th>\n",
       "      <th>Blankfein Positive</th>\n",
       "      <th>Blankfein Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-25 12:35:16</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.176</td>\n",
       "      <td>throughout these topsy-turvy times of scary he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-23 15:36:07</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>former goldman sachs \\r\\ngs, -1.05%\\r\\nboss ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-23 12:21:34</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.000</td>\n",
       "      <td>update: ignore all of the below, because momen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-23 10:25:40</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.148</td>\n",
       "      <td>even as the us stock market continued its free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-23 10:14:09</td>\n",
       "      <td>-0.8555</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.000</td>\n",
       "      <td>london/sydney/hong kong — financial markets ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Blankfein Compound  Blankfein Negative  \\\n",
       "0 2020-03-25 12:35:16              0.6808               0.064   \n",
       "1 2020-03-23 15:36:07              0.0000               0.000   \n",
       "2 2020-03-23 12:21:34             -0.3612               0.054   \n",
       "3 2020-03-23 10:25:40              0.7003               0.029   \n",
       "4 2020-03-23 10:14:09             -0.8555               0.234   \n",
       "\n",
       "   Blankfein Neutral  Blankfein Positive  \\\n",
       "0              0.760               0.176   \n",
       "1              1.000               0.000   \n",
       "2              0.946               0.000   \n",
       "3              0.823               0.148   \n",
       "4              0.766               0.000   \n",
       "\n",
       "                                      Blankfein Text  \n",
       "0  throughout these topsy-turvy times of scary he...  \n",
       "1  former goldman sachs \\r\\ngs, -1.05%\\r\\nboss ll...  \n",
       "2  update: ignore all of the below, because momen...  \n",
       "3  even as the us stock market continued its free...  \n",
       "4  london/sydney/hong kong — financial markets ar...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Lloyd Blankfein sentiment scores DataFrame\n",
    "blankfein_SP500_sentiments = []\n",
    "\n",
    "for blankfein_SP500_article in blankfein_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = blankfein_SP500_article['publishedAt']\n",
    "        text = blankfein_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        blankfein_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Blankfein Text\": text,\n",
    "            \"Blankfein Compound\": compound,\n",
    "            \"Blankfein Positive\": pos,\n",
    "            \"Blankfein Negative\": neg,\n",
    "            \"Blankfein Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "blankfein_SP500_df = pd.DataFrame(blankfein_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Blankfein Compound\",\"Blankfein Negative\",\"Blankfein Neutral\",\"Blankfein Positive\",\"Blankfein Text\"]\n",
    "blankfein_SP500_df = blankfein_SP500_df[cols]\n",
    "\n",
    "\n",
    "blankfein_SP500_df['Date'] = pd.to_datetime(blankfein_SP500_df['Date'], infer_datetime_format=True)\n",
    "#blankfein_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "blankfein_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Solomon Compound</th>\n",
       "      <th>Solomon Negative</th>\n",
       "      <th>Solomon Neutral</th>\n",
       "      <th>Solomon Positive</th>\n",
       "      <th>Solomon Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-10 17:09:43</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.041</td>\n",
       "      <td>four star films,box office hits,indies and imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-09 02:21:52</td>\n",
       "      <td>-0.7351</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.000</td>\n",
       "      <td>there is no doubt coronavirus has hit the asx ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-02 12:00:00</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.070</td>\n",
       "      <td>editors note: morning money is a free version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01 04:24:30</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>apple inc., formerly apple computer, inc., is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-30 18:16:13</td>\n",
       "      <td>-0.7184</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.069</td>\n",
       "      <td>as a global health crisis raged outside, and m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Solomon Compound  Solomon Negative  Solomon Neutral  \\\n",
       "0 2020-04-10 17:09:43            0.2023             0.000            0.959   \n",
       "1 2020-04-09 02:21:52           -0.7351             0.149            0.851   \n",
       "2 2020-04-02 12:00:00            0.5106             0.000            0.930   \n",
       "3 2020-04-01 04:24:30            0.0000             0.000            1.000   \n",
       "4 2020-03-30 18:16:13           -0.7184             0.157            0.774   \n",
       "\n",
       "   Solomon Positive                                       Solomon Text  \n",
       "0             0.041  four star films,box office hits,indies and imp...  \n",
       "1             0.000  there is no doubt coronavirus has hit the asx ...  \n",
       "2             0.070  editors note: morning money is a free version ...  \n",
       "3             0.000  apple inc., formerly apple computer, inc., is ...  \n",
       "4             0.069  as a global health crisis raged outside, and m...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the David Solomon sentiment scores DataFrame\n",
    "solomon_SP500_sentiments = []\n",
    "\n",
    "for solomon_SP500_article in solomon_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = solomon_SP500_article['publishedAt']\n",
    "        text = solomon_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        solomon_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Solomon Text\": text,\n",
    "            \"Solomon Compound\": compound,\n",
    "            \"Solomon Positive\": pos,\n",
    "            \"Solomon Negative\": neg,\n",
    "            \"Solomon Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "solomon_SP500_df = pd.DataFrame(solomon_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Solomon Compound\",\"Solomon Negative\",\"Solomon Neutral\",\"Solomon Positive\",\"Solomon Text\"]\n",
    "solomon_SP500_df = solomon_SP500_df[cols]\n",
    "\n",
    "solomon_SP500_df['Date'] = pd.to_datetime(solomon_SP500_df['Date'], infer_datetime_format=True)\n",
    "#solomon_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "solomon_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Corbat Compound</th>\n",
       "      <th>Corbat Negative</th>\n",
       "      <th>Corbat Neutral</th>\n",
       "      <th>Corbat Positive</th>\n",
       "      <th>Corbat Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-04 14:34:03</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.051</td>\n",
       "      <td>a man cleans up on the trading floor, followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-17 10:44:09</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.082</td>\n",
       "      <td>the covid-19 crash has engulfed the big financ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Corbat Compound  Corbat Negative  Corbat Neutral  \\\n",
       "0 2020-04-04 14:34:03           0.3182            0.000           0.949   \n",
       "1 2020-03-17 10:44:09           0.0772            0.055           0.862   \n",
       "\n",
       "   Corbat Positive                                        Corbat Text  \n",
       "0            0.051  a man cleans up on the trading floor, followin...  \n",
       "1            0.082  the covid-19 crash has engulfed the big financ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Michael Corbat sentiment scores DataFrame\n",
    "corbat_SP500_sentiments = []\n",
    "\n",
    "for corbat_SP500_article in corbat_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = corbat_SP500_article['publishedAt']\n",
    "        text = corbat_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        corbat_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Corbat Text\": text,\n",
    "            \"Corbat Compound\": compound,\n",
    "            \"Corbat Positive\": pos,\n",
    "            \"Corbat Negative\": neg,\n",
    "            \"Corbat Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "corbat_SP500_df = pd.DataFrame(corbat_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Corbat Compound\",\"Corbat Negative\",\"Corbat Neutral\",\"Corbat Positive\",\"Corbat Text\"]\n",
    "corbat_SP500_df = corbat_SP500_df[cols]\n",
    "\n",
    "corbat_SP500_df['Date'] = pd.to_datetime(corbat_SP500_df['Date'], infer_datetime_format=True)\n",
    "#corbat_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "corbat_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Lead economists Compound</th>\n",
       "      <th>Lead economists Negative</th>\n",
       "      <th>Lead economists Neutral</th>\n",
       "      <th>Lead economists Positive</th>\n",
       "      <th>Lead economists Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 11:04:42</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.066</td>\n",
       "      <td>global stocks jumped and us equity futures tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-13 20:32:00</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.213</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;us stocks slid on monday in their firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-13 15:50:33</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.104</td>\n",
       "      <td>in the spring of 1944, as the allies secretly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-13 13:28:24</td>\n",
       "      <td>-0.2617</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.081</td>\n",
       "      <td>for fans of american football, it is unfortuna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-13 01:14:04</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.167</td>\n",
       "      <td>new york: wall street closed out its best week...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Lead economists Compound  Lead economists Negative  \\\n",
       "0 2020-04-14 11:04:42                    0.4404                     0.000   \n",
       "1 2020-04-13 20:32:00                    0.8020                     0.053   \n",
       "2 2020-04-13 15:50:33                    0.6369                     0.000   \n",
       "3 2020-04-13 13:28:24                   -0.2617                     0.119   \n",
       "4 2020-04-13 01:14:04                    0.8126                     0.000   \n",
       "\n",
       "   Lead economists Neutral  Lead economists Positive  \\\n",
       "0                    0.934                     0.066   \n",
       "1                    0.733                     0.213   \n",
       "2                    0.896                     0.104   \n",
       "3                    0.800                     0.081   \n",
       "4                    0.833                     0.167   \n",
       "\n",
       "                                Lead economists Text  \n",
       "0  global stocks jumped and us equity futures tra...  \n",
       "1  <ul><li>us stocks slid on monday in their firs...  \n",
       "2  in the spring of 1944, as the allies secretly ...  \n",
       "3  for fans of american football, it is unfortuna...  \n",
       "4  new york: wall street closed out its best week...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the lead economists sentiment scores DataFrame\n",
    "economists_SP500_sentiments = []\n",
    "\n",
    "for economists_SP500_article in economists_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = economists_SP500_article['publishedAt']\n",
    "        text = economists_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        economists_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Lead economists Text\": text,\n",
    "            \"Lead economists Compound\": compound,\n",
    "            \"Lead economists Positive\": pos,\n",
    "            \"Lead economists Negative\": neg,\n",
    "            \"Lead economists Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "economists_SP500_df = pd.DataFrame(economists_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Lead economists Compound\",\"Lead economists Negative\",\"Lead economists Neutral\",\"Lead economists Positive\",\"Lead economists Text\"]\n",
    "economists_SP500_df = economists_SP500_df[cols]\n",
    "\n",
    "economists_SP500_df['Date'] = pd.to_datetime(economists_SP500_df['Date'], infer_datetime_format=True)\n",
    "#economists_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "economists_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Powell Compound</th>\n",
       "      <th>Powell Negative</th>\n",
       "      <th>Powell Neutral</th>\n",
       "      <th>Powell Positive</th>\n",
       "      <th>Powell Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-16 11:30:55</td>\n",
       "      <td>0.6652</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.138</td>\n",
       "      <td>wolf richter wolfstreet.com, www.amazon.com/au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Powell Compound  Powell Negative  Powell Neutral  \\\n",
       "0 2020-03-16 11:30:55           0.6652            0.039           0.823   \n",
       "\n",
       "   Powell Positive                                        Powell Text  \n",
       "0            0.138  wolf richter wolfstreet.com, www.amazon.com/au...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Jerome Powel sentiment scores DataFrame\n",
    "powel_SP500_sentiments = []\n",
    "\n",
    "for powel_SP500_article in powel_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = powel_SP500_article['publishedAt']\n",
    "        text = powel_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        powel_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Powell Text\": text,\n",
    "            \"Powell Compound\": compound,\n",
    "            \"Powell Positive\": pos,\n",
    "            \"Powell Negative\": neg,\n",
    "            \"Powell Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "powel_SP500_df = pd.DataFrame(powel_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Powell Compound\",\"Powell Negative\",\"Powell Neutral\",\"Powell Positive\",\"Powell Text\"]\n",
    "powel_SP500_df = powel_SP500_df[cols]\n",
    "\n",
    "powel_SP500_df ['Date'] = pd.to_datetime(powel_SP500_df ['Date'], infer_datetime_format=True)\n",
    "#powel_SP500_df .set_index(('Date'), inplace=True)\n",
    "\n",
    "powel_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>FED Compound</th>\n",
       "      <th>FED Negative</th>\n",
       "      <th>FED Neutral</th>\n",
       "      <th>FED Positive</th>\n",
       "      <th>FED Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 15:03:54</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.044</td>\n",
       "      <td>us stocks have risen sharply in early trading ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14 14:22:20</td>\n",
       "      <td>-0.6667</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>emerging-markets investing pioneer mark mobius...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14 14:05:52</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.045</td>\n",
       "      <td>the stock market's coronavirus-fueled declines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14 14:01:49</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.053</td>\n",
       "      <td>rising credit losses for banks suggest rally i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-14 13:43:12</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.052</td>\n",
       "      <td>further action needed.\\r\\nmonetary/fiscal stim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  FED Compound  FED Negative  FED Neutral  FED Positive  \\\n",
       "0 2020-04-14 15:03:54        0.2500         0.000        0.956         0.044   \n",
       "1 2020-04-14 14:22:20       -0.6667         0.126        0.874         0.000   \n",
       "2 2020-04-14 14:05:52        0.2716         0.000        0.955         0.045   \n",
       "3 2020-04-14 14:01:49       -0.2732         0.095        0.852         0.053   \n",
       "4 2020-04-14 13:43:12       -0.6124         0.156        0.792         0.052   \n",
       "\n",
       "                                            FED Text  \n",
       "0  us stocks have risen sharply in early trading ...  \n",
       "1  emerging-markets investing pioneer mark mobius...  \n",
       "2  the stock market's coronavirus-fueled declines...  \n",
       "3  rising credit losses for banks suggest rally i...  \n",
       "4  further action needed.\\r\\nmonetary/fiscal stim...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the FED officials sentiment scores DataFrame\n",
    "fed_SP500_sentiments = []\n",
    "\n",
    "for fed_SP500_article in fed_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = fed_SP500_article['publishedAt']\n",
    "        text = fed_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        fed_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"FED Text\": text,\n",
    "            \"FED Compound\": compound,\n",
    "            \"FED Positive\": pos,\n",
    "            \"FED Negative\": neg,\n",
    "            \"FED Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "fed_SP500_df = pd.DataFrame(fed_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"FED Compound\",\"FED Negative\",\"FED Neutral\",\"FED Positive\",\"FED Text\"]\n",
    "fed_SP500_df = fed_SP500_df[cols]\n",
    "\n",
    "fed_SP500_df['Date'] = pd.to_datetime(fed_SP500_df['Date'], infer_datetime_format=True)\n",
    "#fed_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "fed_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Fink Compound</th>\n",
       "      <th>Fink Negative</th>\n",
       "      <th>Fink Neutral</th>\n",
       "      <th>Fink Positive</th>\n",
       "      <th>Fink Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 01:25:00</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.121</td>\n",
       "      <td>larry fink was not exactly a household name un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-10 12:56:20</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.052</td>\n",
       "      <td>investment management giant blackrock inc.\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-10 12:02:12</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.077</td>\n",
       "      <td>blackrock increased the pay of larry fink, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-09 13:37:29</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.109</td>\n",
       "      <td>we have an opportunity to build a better econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-07 08:00:01</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>going linux · show notes\\r\\n2020 episodes:\\r\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date  Fink Compound  Fink Negative  Fink Neutral  \\\n",
       "0 2020-04-14 01:25:00         0.7351          0.000         0.879   \n",
       "1 2020-04-10 12:56:20        -0.0772          0.082         0.867   \n",
       "2 2020-04-10 12:02:12         0.2500          0.056         0.867   \n",
       "3 2020-04-09 13:37:29         0.0772          0.084         0.806   \n",
       "4 2020-04-07 08:00:01         0.0000          0.000         1.000   \n",
       "\n",
       "   Fink Positive                                          Fink Text  \n",
       "0          0.121  larry fink was not exactly a household name un...  \n",
       "1          0.052  investment management giant blackrock inc.\\r\\n...  \n",
       "2          0.077  blackrock increased the pay of larry fink, its...  \n",
       "3          0.109  we have an opportunity to build a better econo...  \n",
       "4          0.000  going linux · show notes\\r\\n2020 episodes:\\r\\n...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Larry Fink sentiment scores DataFrame\n",
    "fink_SP500_sentiments = []\n",
    "\n",
    "for fink_SP500_article in fink_SP500_headlines[\"articles\"]:\n",
    "    try:\n",
    "        date = fink_SP500_article['publishedAt']\n",
    "        text = fink_SP500_article[\"content\"].lower()    \n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        fink_SP500_sentiments.append({\n",
    "            \"Date\": date,\n",
    "            \"Fink Text\": text,\n",
    "            \"Fink Compound\": compound,\n",
    "            \"Fink Positive\": pos,\n",
    "            \"Fink Negative\": neg,\n",
    "            \"Fink Neutral\": neu,  \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "fink_SP500_df = pd.DataFrame(fink_SP500_sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Date\", \"Fink Compound\",\"Fink Negative\",\"Fink Neutral\",\"Fink Positive\",\"Fink Text\"]\n",
    "fink_SP500_df = fink_SP500_df[cols]\n",
    "\n",
    "fink_SP500_df['Date'] = pd.to_datetime(fink_SP500_df['Date'], infer_datetime_format=True)\n",
    "#fink_SP500_df.set_index(('Date'), inplace=True)\n",
    "\n",
    "fink_SP500_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SP500 Compound</th>\n",
       "      <th>SP500 Negative</th>\n",
       "      <th>SP500 Neutral</th>\n",
       "      <th>SP500 Positive</th>\n",
       "      <th>SP500 Text</th>\n",
       "      <th>Cramer Compound</th>\n",
       "      <th>Cramer Negative</th>\n",
       "      <th>Cramer Neutral</th>\n",
       "      <th>Cramer Positive</th>\n",
       "      <th>...</th>\n",
       "      <th>FED Compound</th>\n",
       "      <th>FED Negative</th>\n",
       "      <th>FED Neutral</th>\n",
       "      <th>FED Positive</th>\n",
       "      <th>FED Text</th>\n",
       "      <th>Fink Compound</th>\n",
       "      <th>Fink Negative</th>\n",
       "      <th>Fink Neutral</th>\n",
       "      <th>Fink Positive</th>\n",
       "      <th>Fink Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-14 15:55:21</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.000</td>\n",
       "      <td>the parnassus endeavor fund (trades, portfolio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-14 15:43:51</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.047</td>\n",
       "      <td>looking at the chart below, it’s fair to say t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-14 15:40:28</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.059</td>\n",
       "      <td>stock futures, premarket data and performance ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-14 15:40:27</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.128</td>\n",
       "      <td>tuesday morning brought some relief for invest...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-14 15:29:43</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>its been a rough couple of months for all inve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-03-24 14:57:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1779</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.053</td>\n",
       "      <td>&lt;ul&gt;&lt;li&gt;top executives sold a total of $us9.2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-03-18 17:18:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.093</td>\n",
       "      <td>legendary corporate raider carl icahn warned t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-03-18 08:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.147</td>\n",
       "      <td>as investors prepare for the 2020 proxy voting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-03-18 08:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.147</td>\n",
       "      <td>as investors prepare for the 2020 proxy voting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-03-17 08:00:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>going linux · show notes\\r\\n2020 episodes:\\r\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date  SP500 Compound  SP500 Negative  SP500 Neutral  \\\n",
       "0  2020-04-14 15:55:21         -0.1779           0.045          0.955   \n",
       "1  2020-04-14 15:43:51          0.3182           0.000          0.953   \n",
       "2  2020-04-14 15:40:28          0.1027           0.049          0.892   \n",
       "3  2020-04-14 15:40:27          0.6908           0.000          0.872   \n",
       "4  2020-04-14 15:29:43          0.0000           0.000          1.000   \n",
       "..                 ...             ...             ...            ...   \n",
       "13 2020-03-24 14:57:14             NaN             NaN            NaN   \n",
       "14 2020-03-18 17:18:17             NaN             NaN            NaN   \n",
       "15 2020-03-18 08:30:00             NaN             NaN            NaN   \n",
       "16 2020-03-18 08:30:00             NaN             NaN            NaN   \n",
       "17 2020-03-17 08:00:01             NaN             NaN            NaN   \n",
       "\n",
       "    SP500 Positive                                         SP500 Text  \\\n",
       "0            0.000  the parnassus endeavor fund (trades, portfolio...   \n",
       "1            0.047  looking at the chart below, it’s fair to say t...   \n",
       "2            0.059  stock futures, premarket data and performance ...   \n",
       "3            0.128  tuesday morning brought some relief for invest...   \n",
       "4            0.000  its been a rough couple of months for all inve...   \n",
       "..             ...                                                ...   \n",
       "13             NaN                                                NaN   \n",
       "14             NaN                                                NaN   \n",
       "15             NaN                                                NaN   \n",
       "16             NaN                                                NaN   \n",
       "17             NaN                                                NaN   \n",
       "\n",
       "    Cramer Compound  Cramer Negative  Cramer Neutral  Cramer Positive  ...  \\\n",
       "0               NaN              NaN             NaN              NaN  ...   \n",
       "1               NaN              NaN             NaN              NaN  ...   \n",
       "2               NaN              NaN             NaN              NaN  ...   \n",
       "3               NaN              NaN             NaN              NaN  ...   \n",
       "4               NaN              NaN             NaN              NaN  ...   \n",
       "..              ...              ...             ...              ...  ...   \n",
       "13              NaN              NaN             NaN              NaN  ...   \n",
       "14              NaN              NaN             NaN              NaN  ...   \n",
       "15              NaN              NaN             NaN              NaN  ...   \n",
       "16              NaN              NaN             NaN              NaN  ...   \n",
       "17              NaN              NaN             NaN              NaN  ...   \n",
       "\n",
       "   FED Compound  FED Negative  FED Neutral  FED Positive  FED Text  \\\n",
       "0           NaN           NaN          NaN           NaN       NaN   \n",
       "1           NaN           NaN          NaN           NaN       NaN   \n",
       "2           NaN           NaN          NaN           NaN       NaN   \n",
       "3           NaN           NaN          NaN           NaN       NaN   \n",
       "4           NaN           NaN          NaN           NaN       NaN   \n",
       "..          ...           ...          ...           ...       ...   \n",
       "13          NaN           NaN          NaN           NaN       NaN   \n",
       "14          NaN           NaN          NaN           NaN       NaN   \n",
       "15          NaN           NaN          NaN           NaN       NaN   \n",
       "16          NaN           NaN          NaN           NaN       NaN   \n",
       "17          NaN           NaN          NaN           NaN       NaN   \n",
       "\n",
       "   Fink Compound  Fink Negative  Fink Neutral  Fink Positive  \\\n",
       "0            NaN            NaN           NaN            NaN   \n",
       "1            NaN            NaN           NaN            NaN   \n",
       "2            NaN            NaN           NaN            NaN   \n",
       "3            NaN            NaN           NaN            NaN   \n",
       "4            NaN            NaN           NaN            NaN   \n",
       "..           ...            ...           ...            ...   \n",
       "13       -0.1779          0.092         0.855          0.053   \n",
       "14       -0.0772          0.099         0.807          0.093   \n",
       "15        0.7506          0.000         0.853          0.147   \n",
       "16        0.7506          0.000         0.853          0.147   \n",
       "17        0.0000          0.000         1.000          0.000   \n",
       "\n",
       "                                            Fink Text  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "..                                                ...  \n",
       "13  <ul><li>top executives sold a total of $us9.2 ...  \n",
       "14  legendary corporate raider carl icahn warned t...  \n",
       "15  as investors prepare for the 2020 proxy voting...  \n",
       "16  as investors prepare for the 2020 proxy voting...  \n",
       "17  going linux · show notes\\r\\n2020 episodes:\\r\\n...  \n",
       "\n",
       "[328 rows x 56 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_500_df = pd.concat([SP500_df, cramer_SP500_df, potus_SP500_df, dimon_SP500_df, blankfein_SP500_df, solomon_SP500_df, corbat_SP500_df, \n",
    "                        economists_SP500_df, powel_SP500_df,fed_SP500_df,fink_SP500_df])\n",
    "#all_500_df = all_500_df.replace(np.nan, 0)\n",
    "all_500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                        datetime64[ns]\n",
       "SP500 Compound                     float64\n",
       "SP500 Negative                     float64\n",
       "SP500 Neutral                      float64\n",
       "SP500 Positive                     float64\n",
       "SP500 Text                          object\n",
       "Cramer Compound                    float64\n",
       "Cramer Negative                    float64\n",
       "Cramer Neutral                     float64\n",
       "Cramer Positive                    float64\n",
       "Cramer Text                         object\n",
       "Trump Compound                     float64\n",
       "Trump Negative                     float64\n",
       "Trump Neutral                      float64\n",
       "Trump Positive                     float64\n",
       "Trump Text                          object\n",
       "Dimon Compound                     float64\n",
       "Dimon Negative                     float64\n",
       "Dimon Neutral                      float64\n",
       "Dimon Positive                     float64\n",
       "Dimon Text                          object\n",
       "Blankfein Compound                 float64\n",
       "Blankfein Negative                 float64\n",
       "Blankfein Neutral                  float64\n",
       "Blankfein Positive                 float64\n",
       "Blankfein Text                      object\n",
       "Solomon Compound                   float64\n",
       "Solomon Negative                   float64\n",
       "Solomon Neutral                    float64\n",
       "Solomon Positive                   float64\n",
       "Solomon Text                        object\n",
       "Corbat Compound                    float64\n",
       "Corbat Negative                    float64\n",
       "Corbat Neutral                     float64\n",
       "Corbat Positive                    float64\n",
       "Corbat Text                         object\n",
       "Lead economists Compound           float64\n",
       "Lead economists Negative           float64\n",
       "Lead economists Neutral            float64\n",
       "Lead economists Positive           float64\n",
       "Lead economists Text                object\n",
       "Powell Compound                    float64\n",
       "Powell Negative                    float64\n",
       "Powell Neutral                     float64\n",
       "Powell Positive                    float64\n",
       "Powell Text                         object\n",
       "FED Compound                       float64\n",
       "FED Negative                       float64\n",
       "FED Neutral                        float64\n",
       "FED Positive                       float64\n",
       "FED Text                            object\n",
       "Fink Compound                      float64\n",
       "Fink Negative                      float64\n",
       "Fink Neutral                       float64\n",
       "Fink Positive                      float64\n",
       "Fink Text                           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_500_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_500_df.to_csv(\"export_sent1_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save to pickle\n",
    "\n",
    "all_500_df = \"all_sent_pickle_0414\"  # stores merged_df as merged_df_pickle\n",
    "outfile = open(all_500_df, \"wb\")  # saves into pickle\n",
    "pickle.dump(all_500_df, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_500_df['Date'] = pd.to_datetime(all_500_df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_500_df['Date'] = pd.to_datetime(all_500_df['Date'], infer_datetime_format=True)\n",
    "all_500_df.set_index(('Date'), inplace=True)\n",
    "all_500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed\n",
    "#UPON A DECISION  POLYNOMIAL OR GET DUMMIES\n",
    "#all_500_df_dummy = pd.get_dummies(all_500_df)\n",
    "#all_500_df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_500_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the S&P 500 Sentiment\n",
    "SP500_df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the S&P 500 Sentiment by Jim Cramer \n",
    "fed_SP500_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the S&P 500 Sentiment by Donald Trump \n",
    "potus_SP500_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "In this section, we used NLTK and Python to tokenize the text for each option. \n",
    "1. Lowercase each word\n",
    "2. Remove Punctuation\n",
    "3. Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the default stopwords list if necessary\n",
    "stop_words_ = {'cat','char', 'ha','u','wa', 'dead'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the tokenizer function\n",
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    # Create a list of the words\n",
    "    sw = set(stopwords.words('english'))\n",
    "     # Remove the non-alpha characters # Substitute everything that is NOT a letter with empty string\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    re_clean = regex.sub('', text)\n",
    "    words = word_tokenize(re_clean)\n",
    "   \n",
    "    # Lemmatize Words into root words\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    #convert to lower case and remove the stopwords \n",
    "    tokens = [word.lower() for word in lem if word.lower() not in sw.union(stop_words_)]\n",
    "    \n",
    "    return tokens\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500\n",
    "SP500_tokens = SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in SP500_tokens['SP500 Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'SP500  tokens':tokenized_articles})\n",
    "\n",
    "SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "SP500_tokens['SP500  Tokens'] = SP500_tokens_df \n",
    "\n",
    "SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by Jim Cramer\n",
    "\n",
    "cramer_SP500_tokens = cramer_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in cramer_SP500_tokens['Cramer Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Cramer tokens':tokenized_articles})\n",
    "\n",
    "cramer_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "cramer_SP500_tokens['Cramer Tokens'] = cramer_SP500_tokens_df \n",
    "\n",
    "cramer_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by Donald Trump\n",
    "\n",
    "potus_SP500_tokens = potus_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in potus_SP500_tokens['Trump Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Trump tokens':tokenized_articles})\n",
    "\n",
    "potus_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "potus_SP500_tokens['Trump Tokens'] = potus_SP500_tokens_df \n",
    "\n",
    "potus_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by Jaimie Dimon\n",
    "\n",
    "dimon_SP500_tokens = dimon_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in dimon_SP500_tokens['Dimon Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Dimon tokens':tokenized_articles})\n",
    "\n",
    "dimon_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "dimon_SP500_tokens['Dimon Tokens'] = dimon_SP500_tokens_df \n",
    "\n",
    "dimon_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by Lloyd Blankfein \n",
    "\n",
    "blankfein_SP500_tokens = blankfein_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in blankfein_SP500_tokens['Blankfein Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Blankfein tokens':tokenized_articles})\n",
    "\n",
    "blankfein_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "blankfein_SP500_tokens['Blankfein Tokens'] = blankfein_SP500_tokens_df \n",
    "\n",
    "blankfein_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by David Solomon\n",
    "\n",
    "solomon_SP500_tokens = solomon_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in solomon_SP500_tokens['Solomon Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Solomon tokens':tokenized_articles})\n",
    "\n",
    "solomon_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "solomon_SP500_tokens['Solomon Tokens'] = solomon_SP500_tokens_df \n",
    "\n",
    "solomon_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by Michael Corbat\n",
    "\n",
    "corbat_SP500_tokens = corbat_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in corbat_SP500_tokens['Corbat Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Corbat tokens':tokenized_articles})\n",
    "\n",
    "corbat_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "corbat_SP500_tokens['Corbat Tokens'] = corbat_SP500_tokens_df \n",
    "\n",
    "corbat_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by lead economists\n",
    "\n",
    "economists_SP500_tokens = economists_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in economists_SP500_tokens['Lead economists Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Lead economists tokens':tokenized_articles})\n",
    "\n",
    "economists_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "economists_SP500_tokens['Lead economists Tokens'] = economists_SP500_tokens_df \n",
    "\n",
    "economists_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by Jerome Powel\n",
    "\n",
    "powel_SP500_tokens = powel_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in powel_SP500_tokens['Powell Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Powell tokens':tokenized_articles})\n",
    "\n",
    "powel_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "powel_SP500_tokens['Powell Tokens'] = powel_SP500_tokens_df \n",
    "\n",
    "powel_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by FED officials\n",
    "\n",
    "fed_SP500_tokens = fed_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in fed_SP500_tokens['FED Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'FED tokens':tokenized_articles})\n",
    "\n",
    "fed_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "fed_SP500_tokens['FED Tokens'] = fed_SP500_tokens_df \n",
    "\n",
    "fed_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for S&P 500 by Larry Fink\n",
    "\n",
    "fink_SP500_tokens = fink_SP500_df.copy()\n",
    "tokenized = []\n",
    "for i in fink_SP500_tokens['Fink Text']:\n",
    "    tokenized_articles = tokenizer(i)\n",
    "    tokenized.append({'Fink tokens':tokenized_articles})\n",
    "\n",
    "fink_SP500_tokens_df= pd.DataFrame(tokenized)\n",
    "fink_SP500_tokens['FED Tokens'] = fink_SP500_tokens_df \n",
    "\n",
    "fink_SP500_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_df = pd.concat([SP500_tokens, cramer_SP500_tokens, potus_SP500_tokens, dimon_SP500_tokens, blankfein_SP500_tokens, solomon_SP500_tokens, \n",
    "                           corbat_SP500_tokens, economists_SP500_tokens, powel_SP500_tokens, fed_SP500_tokens, fink_SP500_tokens])\n",
    "\n",
    "all_tokens_df= all_tokens_df.replace(np.nan, 0)\n",
    "all_tokens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the database for polynomial features if we decide to use it\n",
    "all_ = all_500_df.drop(columns =['SP500 Text', 'Cramer Text', 'Trump Text', 'Dimon Text', 'Blankfein Text', \n",
    "                                 'Solomon Text', 'Corbat Text', 'Lead economists Text', 'Powell Text', 'FED Text', 'Fink Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPON A DECISION  POLYNOMIAL OR GET DUMMIES\n",
    "#in case we wanted to use as a preporcesing polynomial features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "print(poly.fit_transform(all_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGrams and Frequency Analysis\n",
    "\n",
    "In this section we are looking at the ngrams and word frequency for each option. \n",
    "\n",
    "1. Use NLTK to produce the n-grams for N = 2. \n",
    "2. List the top 10 words for each option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2\n",
    "SP500_words_all = []\n",
    "for text in SP500_tokens['SP500  Tokens']:\n",
    "    for word in text:\n",
    "        SP500_words_all.append(word)\n",
    "SP500_word_counts = Counter(ngrams(SP500_words_all, n=2))\n",
    "SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2 by FED officials\n",
    "fed_SP500_words_all = []\n",
    "for text in fed_SP500_tokens['FED Tokens']:\n",
    "    for word in text:\n",
    "        fed_SP500_words_all.append(word)\n",
    "fed_SP500_word_counts = Counter(ngrams(fed_SP500_words_all, n=2))\n",
    "fed_SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2 by Donald Trump\n",
    "potus_SP500_words_all = []\n",
    "for text in potus_SP500_tokens['Trump Tokens']:\n",
    "    for word in text:\n",
    "        potus_SP500_words_all.append(word)\n",
    "potus_SP500_word_counts = Counter(ngrams(potus_SP500_words_all, n=2))\n",
    "potus_SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2 by Jamie Dimon\n",
    "dimon_SP500_words_all = []\n",
    "for text in dimon_SP500_tokens['Dimon Tokens']:\n",
    "    for word in text:\n",
    "        dimon_SP500_words_all.append(word)\n",
    "dimon_SP500_word_counts = Counter(ngrams(dimon_SP500_words_all, n=3))\n",
    "dimon_SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2 by Lloyd Blankfein\n",
    "blankfein_SP500_words_all = []\n",
    "for text in blankfein_SP500_tokens['Blankfein Tokens']:\n",
    "    for word in text:\n",
    "        blankfein_SP500_words_all.append(word)\n",
    "blankfein_SP500_word_counts = Counter(ngrams(blankfein_SP500_words_all, n=3))\n",
    "blankfein_SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2 by David Solomon\n",
    "solomon_SP500_words_all = []\n",
    "for text in solomon_SP500_tokens['Solomon Tokens']:\n",
    "    for word in text:\n",
    "        solomon_SP500_words_all.append(word)\n",
    "solomon_SP500_word_counts = Counter(ngrams(solomon_SP500_words_all, n=3))\n",
    "solomon_SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2 by Michael Corbat\n",
    "corbat_SP500_words_all = []\n",
    "for text in corbat_SP500_tokens['Corbat Tokens']:\n",
    "    for word in text:\n",
    "        corbat_SP500_words_all.append(word)\n",
    "corbat_SP500_word_counts = Counter(ngrams(corbat_SP500_words_all, n=2))\n",
    "corbat_SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 N-grams where N=2 by lead economists\n",
    "economists_SP500_words_all = []\n",
    "for text in economists_SP500_tokens['Lead economists Tokens']:\n",
    "    for word in text:\n",
    "        economists_SP500_words_all.append(word)\n",
    "economists_SP500_word_counts = Counter(ngrams(economists_SP500_words_all, n=2))\n",
    "economists_SP500_word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the token_count function to generate the top 10 words from each option\n",
    "tokens = all_tokens_df\n",
    "def token_count(tokens, N=10):\n",
    "    \n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    \n",
    "    return Counter(tokens).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 words for S&P 500\n",
    "\n",
    "token_count(SP500_words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 words for S&P 500 by Jim Cramer\n",
    "token_count(cramer_SP500_words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 words for S&P 500 by Donald Trump\n",
    "token_count(potus_SP500_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds\n",
    "\n",
    "In this section, we will generate word clouds for each option to summarize the news "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install WordCloud\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [20.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the function\n",
    "def processed_text(corpus): \n",
    "    # Combine all articles in corpus into one large string\n",
    "    big_string = ' '.join(corpus)\n",
    "    return big_string\n",
    "SP500_words = processed_text(SP500_words_all)\n",
    "cramer_SP500_words = processed_text(cramer_SP500_words_all)\n",
    "potus_SP500_words = processed_text(potus_SP500_words_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 word cloud\n",
    "SP500_wc = WordCloud(collocations=False).generate(SP500_words)\n",
    "fig = plt.figure()\n",
    "plt.imshow(SP500_wc)\n",
    "plt.title('Word Cloud - S&P 500', fontsize=30, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 by Jim Cramer word cloud\n",
    "\n",
    "fig = plt.figure()\n",
    "cramer_SP500_wc = WordCloud().generate(cramer_SP500_words)\n",
    "plt.imshow(cramer_SP500_wc)\n",
    "plt.title('Word Cloud - S&P 500 by Jim Cramer', fontsize=30, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the S&P 500 by Donald Trump word cloud\n",
    "\n",
    "fig = plt.figure()\n",
    "potus_SP500_wc = WordCloud().generate(potus_SP500_words)\n",
    "plt.imshow(potus_SP500_wc)\n",
    "plt.title('Word Cloud - S&P 500 by The President - Mr. Donald Trump', fontsize=30, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition for all chosen options for S&P 500\n",
    "\n",
    "In this section, we built a named entity recognition model for all options and visualized the tags using SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "\n",
    "!conda install -c conda-forge spacy\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "#!pnda install -c conda-forge WordCloud\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the S&P 500 text together\n",
    "SP500_sent = []\n",
    "for sent in SP500_tokens['SP500 Text']:\n",
    "    sent_list = sent\n",
    "    SP500_sent.append(sent_list)\n",
    "    \n",
    "one_string_SP500 = ' '.join(SP500_sent)\n",
    "one_string_SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NER processor on all of the text\n",
    "SP500_doc = nlp(one_string_SP500)\n",
    "\n",
    "# Add a title to the document\n",
    "SP500_doc.user_data['title'] = 'S&P 500 NER'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(SP500_doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "for ent in SP500_doc.ents:\n",
    "    print (ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 by Jim Cramer NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Jim Cramer text together\n",
    "cramer_SP500_sent = []\n",
    "for sent in cramer_SP500_tokens['Cramer Text']:\n",
    "    sent_list = sent\n",
    "    cramer_SP500_sent.append(sent_list)\n",
    "    \n",
    "one_string_cramer_SP500 = ' '.join(cramer_SP500_sent)\n",
    "one_string_cramer_SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NER processor on all of the text\n",
    "cramer_SP500_doc = nlp(one_string_cramer_SP500)\n",
    "\n",
    "# Add a title to the document\n",
    "cramer_SP500_doc.user_data['title'] = 'S&P 500 NER by Jim Cramer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(cramer_SP500_doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "for ent in cramer_SP500_doc.ents:\n",
    "    print (ent, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 NER by The President Mr. Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Donald Trump text together\n",
    "potus_SP500_sent = []\n",
    "for sent in potus_SP500_tokens['Trump Text']:\n",
    "    sent_list = sent\n",
    "    potus_SP500_sent.append(sent_list)\n",
    "    \n",
    "one_string_potus_SP500 = ' '.join(potus_SP500_sent)\n",
    "one_string_potus_SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NER processor on all of the text\n",
    "potus_SP500_doc = nlp(one_string_potus_SP500)\n",
    "\n",
    "# Add a title to the document\n",
    "potus_SP500_doc.user_data['title'] = 'S&P 500 NER by Donald Trump'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(potus_SP500_doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "for ent in cramer_SP500_doc.ents:\n",
    "    print (ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all proper python functions are supposed to contain a doc string explaining\n",
    "# what the function does, its params, and its return\n",
    "# this is what is shown when you type help() and a function (or class, or object, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
